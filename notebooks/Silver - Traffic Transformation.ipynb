{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebef5f7-e4e0-4849-b76f-cb2c17cfbbd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = spark.sql(\"describe external location `checkpoints`\").select(\"url\").collect()[0][0]\n",
    "bronze = spark.sql(\"describe external location `bronze`\").select(\"url\").collect()[0][0]\n",
    "silver = spark.sql(\"describe external location `silver`\").select(\"url\").collect()[0][0]\n",
    "env = \"dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc8c5879-d0bc-493d-97a9-a2942a2f5874",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Reading Data from Bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4ba294-16ba-4555-a26d-84bef27f92f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_BronzeTrafficTable(environment):\n",
    "    print('Reading the Bronze Table Data : ',end='')\n",
    "    df_bronzeTraffic = (spark.readStream\n",
    "                    .table(f\"`{environment}-catalog`.`bronze`.raw_traffic\")\n",
    "                    )\n",
    "    print(f'Reading {environment}-catalog.bronze.raw_traffic Success!')\n",
    "    return df_bronzeTraffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb81261f-2d63-41cc-ace3-b54521e340bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Handle Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3148869-9fac-482b-990a-f3ad59a03844",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def remove_Dups(df):\n",
    "    print('Removing Duplicate values: ', end='')\n",
    "    df_dup = df.dropDuplicates()\n",
    "    print('Success!! ')\n",
    "    return df_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b00709aa-937c-4c9d-99b6-fffadf0599c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Handling NULL values by replacing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71efe776-bb52-487e-a117-ac8d45ee2d84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def handle_NULLs(df,columns):\n",
    "    print('Replacing NULL values on String Columns with \"Unknown\" ' , end='')\n",
    "    df_string = df.fillna('Unknown',subset= columns)\n",
    "    print('Successs!! ')\n",
    "\n",
    "    print('Replacing NULL values on Numeric Columns with \"0\" ' , end='')\n",
    "    df_clean = df_string.fillna(0,subset = columns)\n",
    "    print('Success!! ')\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cbef981-2117-497a-a01d-65a2439b6581",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Getting count of Electric vehicles by creating new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e50a8f-f4f6-4d7b-a409-0ebbeb2e3d72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ev_Count(df):\n",
    "    print('Creating Electric Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_ev = df.withColumn('Electric_Vehicles_Count',\n",
    "                            col('EV_Car') + col('EV_Bike')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "748d065e-db91-4b8e-b352-7f7ea1e9e6ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating columns to get Count of all motor vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03a318b3-5abd-4cb0-8b26-fe434909c03c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Motor_Count(df):\n",
    "    print('Creating All Motor Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_motor = df.withColumn('Motor_Vehicles_Count',\n",
    "                            col('Electric_Vehicles_Count') + col('Two_wheeled_motor_vehicles') + col('Cars_and_taxis') + col('Buses_and_coaches') + col('LGV_Type') + col('HGV_Type')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d7dfce5-4243-4809-8d9e-c28848eb5068",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating Transformed Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86b3fac-4e0d-4f11-8c81-f697e1e64f64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_TransformedTime(df):\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print('Creating Transformed Time column : ',end='')\n",
    "    df_timestamp = df.withColumn('Transformed_Time',\n",
    "                      current_timestamp()\n",
    "                      )\n",
    "    print('Success!!')\n",
    "    return df_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bc0ba1f-5367-47a2-979b-3c39aca6496f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Writing the Transformed data to Silver_Traffic Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f7f640-c8e9-4028-9e8a-12ffe86077ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_SilverTable(StreamingDF,environment):\n",
    "    print('Writing the silver_traffic Data : ',end='') \n",
    "\n",
    "    write_StreamSilver = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation',checkpoint+ \"/SilverTrafficLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverTrafficWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}-catalog`.`silver`.`silver_traffic`\"))\n",
    "    \n",
    "    write_StreamSilver.awaitTermination()\n",
    "    print(f'Writing `{environment}-catalog`.`silver`.`silver_traffic` Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e8f0e4b-6031-482b-a2c9-34557cb92cba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Bronze Table Data : Reading dev-catalog.bronze.raw_traffic Success!\nRemoving Duplicate values: Success!! \nReplacing NULL values on String Columns with \"Unknown\" Successs!! \nReplacing NULL values on Numeric Columns with \"0\" Success!! \nCreating Electric Vehicles Count Column : Success!! \nCreating All Motor Vehicles Count Column : Success!! \nCreating Transformed Time column : Success!!\nWriting the silver_traffic Data : Writing `dev-catalog`.`silver`.`silver_traffic` Success!\n"
     ]
    }
   ],
   "source": [
    "## Reading the bronze traffic data\n",
    "\n",
    "df_trafficdata = read_BronzeTrafficTable(env)\n",
    "\n",
    "# To remove duplicate rows\n",
    "\n",
    "df_dups = remove_Dups(df_trafficdata)\n",
    "\n",
    "# To replace any NULL values\n",
    "Allcolumns =df_dups.schema.names\n",
    "df_nulls = handle_NULLs(df_dups,Allcolumns)\n",
    "\n",
    "## To get the total EV_Count\n",
    "\n",
    "df_ev = ev_Count(df_nulls)\n",
    "\n",
    "## To get the Total Motor vehicle count\n",
    "\n",
    "df_motor = Motor_Count(df_ev)\n",
    "\n",
    "## Calling Transformed time function\n",
    "\n",
    "df_final = create_TransformedTime(df_motor)\n",
    "\n",
    "## Writing to silver_traffic\n",
    "\n",
    "write_Traffic_SilverTable(df_final, env)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver - Traffic Transformation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
